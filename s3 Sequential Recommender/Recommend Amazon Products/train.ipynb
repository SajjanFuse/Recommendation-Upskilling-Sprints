{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "import recbole\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_model, get_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    # dataset config : Sequential Recommendation\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'RATING_FIELD' : 'rating',\n",
    "    'load_col':{\n",
    "        'inter': ['user_id', 'item_id','rating', 'timestamp']\n",
    "    },\n",
    "    'ITEM_LIST_LENGTH_FIELD': 'item_length',\n",
    "    'LIST_SUFFIX': '_list',\n",
    "    'MAX_ITEM_LIST_LENGTH': '5',\n",
    "\n",
    "    # model config\n",
    "    'embedding_size': '64',\n",
    "    'hidden_size': '128',\n",
    "    'num_layers': '1',\n",
    "    'dropout_prob': '0.3',\n",
    "    'loss_type': 'CE',\n",
    "\n",
    "    # Training and evaluation config\n",
    "    'epochs': '100',\n",
    "    'train_batch_size': '4096',\n",
    "    'eval_batch_size': '4096',\n",
    "    'train_neg_sample_args': None,\n",
    "    'eval_args':{\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'split': {'LS': 'valid_and_test'},\n",
    "        'mode': 'full',\n",
    "},\n",
    "    'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision'],\n",
    "    'topk': '10',\n",
    "    'valid_metric': 'MRR@10',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Jun 14:44    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/amazon\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 5\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/amazon\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 5\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/amazon\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 5\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/amazon\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 5\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = Config(model='GRU4Rec', dataset='amazon', config_dict=config_dict)\n",
    "\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "d:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon\n",
      "The number of users: 4465\n",
      "Average actions of users: 5.721774193548387\n",
      "The number of items: 20838\n",
      "Average actions of items: 1.2258002591543888\n",
      "The number of inters: 25542\n",
      "The sparsity of the dataset: 99.97254778423475%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Jun 14:44    INFO  amazon\n",
      "The number of users: 4465\n",
      "Average actions of users: 5.721774193548387\n",
      "The number of items: 20838\n",
      "Average actions of items: 1.2258002591543888\n",
      "The number of inters: 25542\n",
      "The sparsity of the dataset: 99.97254778423475%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "amazon\n",
      "The number of users: 4465\n",
      "Average actions of users: 5.721774193548387\n",
      "The number of items: 20838\n",
      "Average actions of items: 1.2258002591543888\n",
      "The number of inters: 25542\n",
      "The sparsity of the dataset: 99.97254778423475%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "amazon\n",
      "The number of users: 4465\n",
      "Average actions of users: 5.721774193548387\n",
      "The number of items: 20838\n",
      "Average actions of items: 1.2258002591543888\n",
      "The number of inters: 25542\n",
      "The sparsity of the dataset: 99.97254778423475%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "amazon\n",
      "The number of users: 4465\n",
      "Average actions of users: 5.721774193548387\n",
      "The number of items: 20838\n",
      "Average actions of items: 1.2258002591543888\n",
      "The number of inters: 25542\n",
      "The sparsity of the dataset: 99.97254778423475%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config)\n",
    "print(dataset)\n",
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Jun 14:44    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "25 Jun 14:44    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size of interaction: 4096\n",
      "    user_id, torch.Size([4096]), cpu, torch.int64\n",
      "    item_id, torch.Size([4096]), cpu, torch.int64\n",
      "    rating, torch.Size([4096]), cpu, torch.float32\n",
      "    timestamp, torch.Size([4096]), cpu, torch.float32\n",
      "    item_length, torch.Size([4096]), cpu, torch.int64\n",
      "    item_id_list, torch.Size([4096, 5]), cpu, torch.int64\n",
      "    rating_list, torch.Size([4096, 5]), cpu, torch.float32\n",
      "    timestamp_list, torch.Size([4096, 5]), cpu, torch.float32\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in train_data:\n",
    "    print(i)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(recbole.model.sequential_recommender.gru4rec.GRU4Rec, device(type='cpu'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru4rec_model = get_model(config[\"model\"])\n",
    "gru4rec_model, config[\"device\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Jun 14:44    INFO  GRU4Rec(\n",
      "  (item_embedding): Embedding(20838, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 1415616\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(20838, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 1415616\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(20838, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 1415616\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(20838, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 1415616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(20838, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters: 1415616\n"
     ]
    }
   ],
   "source": [
    "model = gru4rec_model(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Jun 14:44    INFO  epoch 0 training [time: 4.26s, train loss: 39.7833]\n",
      "epoch 0 training [time: 4.26s, train loss: 39.7833]\n",
      "epoch 0 training [time: 4.26s, train loss: 39.7833]\n",
      "epoch 0 training [time: 4.26s, train loss: 39.7833]\n",
      "25 Jun 14:44    INFO  epoch 0 evaluating [time: 0.21s, valid_score: 0.000200]\n",
      "epoch 0 evaluating [time: 0.21s, valid_score: 0.000200]\n",
      "epoch 0 evaluating [time: 0.21s, valid_score: 0.000200]\n",
      "epoch 0 evaluating [time: 0.21s, valid_score: 0.000200]\n",
      "25 Jun 14:44    INFO  valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0002    ndcg@10 : 0.0004    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0002    ndcg@10 : 0.0004    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0002    ndcg@10 : 0.0004    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0002    ndcg@10 : 0.0004    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "25 Jun 14:44    INFO  Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "25 Jun 14:45    INFO  epoch 1 training [time: 3.96s, train loss: 39.7517]\n",
      "epoch 1 training [time: 3.96s, train loss: 39.7517]\n",
      "epoch 1 training [time: 3.96s, train loss: 39.7517]\n",
      "epoch 1 training [time: 3.96s, train loss: 39.7517]\n",
      "25 Jun 14:45    INFO  epoch 1 evaluating [time: 0.20s, valid_score: 0.000400]\n",
      "epoch 1 evaluating [time: 0.20s, valid_score: 0.000400]\n",
      "epoch 1 evaluating [time: 0.20s, valid_score: 0.000400]\n",
      "epoch 1 evaluating [time: 0.20s, valid_score: 0.000400]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0004    ndcg@10 : 0.0006    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0004    ndcg@10 : 0.0006    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0004    ndcg@10 : 0.0006    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0004    ndcg@10 : 0.0006    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "25 Jun 14:45    INFO  Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "25 Jun 14:45    INFO  epoch 2 training [time: 3.59s, train loss: 39.7247]\n",
      "epoch 2 training [time: 3.59s, train loss: 39.7247]\n",
      "epoch 2 training [time: 3.59s, train loss: 39.7247]\n",
      "epoch 2 training [time: 3.59s, train loss: 39.7247]\n",
      "25 Jun 14:45    INFO  epoch 2 evaluating [time: 0.19s, valid_score: 0.000600]\n",
      "epoch 2 evaluating [time: 0.19s, valid_score: 0.000600]\n",
      "epoch 2 evaluating [time: 0.19s, valid_score: 0.000600]\n",
      "epoch 2 evaluating [time: 0.19s, valid_score: 0.000600]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0006    ndcg@10 : 0.001    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0006    ndcg@10 : 0.001    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0006    ndcg@10 : 0.001    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0006    ndcg@10 : 0.001    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "25 Jun 14:45    INFO  Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "25 Jun 14:45    INFO  epoch 3 training [time: 3.70s, train loss: 39.6927]\n",
      "epoch 3 training [time: 3.70s, train loss: 39.6927]\n",
      "epoch 3 training [time: 3.70s, train loss: 39.6927]\n",
      "epoch 3 training [time: 3.70s, train loss: 39.6927]\n",
      "25 Jun 14:45    INFO  epoch 3 evaluating [time: 0.21s, valid_score: 0.000800]\n",
      "epoch 3 evaluating [time: 0.21s, valid_score: 0.000800]\n",
      "epoch 3 evaluating [time: 0.21s, valid_score: 0.000800]\n",
      "epoch 3 evaluating [time: 0.21s, valid_score: 0.000800]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0008    ndcg@10 : 0.0012    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0008    ndcg@10 : 0.0012    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0008    ndcg@10 : 0.0012    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0008    ndcg@10 : 0.0012    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "25 Jun 14:45    INFO  Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "25 Jun 14:45    INFO  epoch 4 training [time: 3.78s, train loss: 39.6556]\n",
      "epoch 4 training [time: 3.78s, train loss: 39.6556]\n",
      "epoch 4 training [time: 3.78s, train loss: 39.6556]\n",
      "epoch 4 training [time: 3.78s, train loss: 39.6556]\n",
      "25 Jun 14:45    INFO  epoch 4 evaluating [time: 0.19s, valid_score: 0.001500]\n",
      "epoch 4 evaluating [time: 0.19s, valid_score: 0.001500]\n",
      "epoch 4 evaluating [time: 0.19s, valid_score: 0.001500]\n",
      "epoch 4 evaluating [time: 0.19s, valid_score: 0.001500]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0021    mrr@10 : 0.0015    ndcg@10 : 0.0017    hit@10 : 0.0021    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0021    mrr@10 : 0.0015    ndcg@10 : 0.0017    hit@10 : 0.0021    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0021    mrr@10 : 0.0015    ndcg@10 : 0.0017    hit@10 : 0.0021    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0021    mrr@10 : 0.0015    ndcg@10 : 0.0017    hit@10 : 0.0021    precision@10 : 0.0002\n",
      "25 Jun 14:45    INFO  Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "25 Jun 14:45    INFO  epoch 5 training [time: 3.54s, train loss: 39.6087]\n",
      "epoch 5 training [time: 3.54s, train loss: 39.6087]\n",
      "epoch 5 training [time: 3.54s, train loss: 39.6087]\n",
      "epoch 5 training [time: 3.54s, train loss: 39.6087]\n",
      "25 Jun 14:45    INFO  epoch 5 evaluating [time: 0.19s, valid_score: 0.001500]\n",
      "epoch 5 evaluating [time: 0.19s, valid_score: 0.001500]\n",
      "epoch 5 evaluating [time: 0.19s, valid_score: 0.001500]\n",
      "epoch 5 evaluating [time: 0.19s, valid_score: 0.001500]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0017    mrr@10 : 0.0015    ndcg@10 : 0.0015    hit@10 : 0.0017    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0017    mrr@10 : 0.0015    ndcg@10 : 0.0015    hit@10 : 0.0017    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0017    mrr@10 : 0.0015    ndcg@10 : 0.0015    hit@10 : 0.0017    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0017    mrr@10 : 0.0015    ndcg@10 : 0.0015    hit@10 : 0.0017    precision@10 : 0.0002\n",
      "25 Jun 14:45    INFO  Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "25 Jun 14:45    INFO  epoch 6 training [time: 3.67s, train loss: 39.5419]\n",
      "epoch 6 training [time: 3.67s, train loss: 39.5419]\n",
      "epoch 6 training [time: 3.67s, train loss: 39.5419]\n",
      "epoch 6 training [time: 3.67s, train loss: 39.5419]\n",
      "25 Jun 14:45    INFO  epoch 6 evaluating [time: 0.23s, valid_score: 0.001400]\n",
      "epoch 6 evaluating [time: 0.23s, valid_score: 0.001400]\n",
      "epoch 6 evaluating [time: 0.23s, valid_score: 0.001400]\n",
      "epoch 6 evaluating [time: 0.23s, valid_score: 0.001400]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0017    mrr@10 : 0.0014    ndcg@10 : 0.0015    hit@10 : 0.0017    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0017    mrr@10 : 0.0014    ndcg@10 : 0.0015    hit@10 : 0.0017    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0017    mrr@10 : 0.0014    ndcg@10 : 0.0015    hit@10 : 0.0017    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0017    mrr@10 : 0.0014    ndcg@10 : 0.0015    hit@10 : 0.0017    precision@10 : 0.0002\n",
      "25 Jun 14:45    INFO  epoch 7 training [time: 3.79s, train loss: 39.4148]\n",
      "epoch 7 training [time: 3.79s, train loss: 39.4148]\n",
      "epoch 7 training [time: 3.79s, train loss: 39.4148]\n",
      "epoch 7 training [time: 3.79s, train loss: 39.4148]\n",
      "25 Jun 14:45    INFO  epoch 7 evaluating [time: 0.21s, valid_score: 0.001400]\n",
      "epoch 7 evaluating [time: 0.21s, valid_score: 0.001400]\n",
      "epoch 7 evaluating [time: 0.21s, valid_score: 0.001400]\n",
      "epoch 7 evaluating [time: 0.21s, valid_score: 0.001400]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0021    mrr@10 : 0.0014    ndcg@10 : 0.0016    hit@10 : 0.0021    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0021    mrr@10 : 0.0014    ndcg@10 : 0.0016    hit@10 : 0.0021    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0021    mrr@10 : 0.0014    ndcg@10 : 0.0016    hit@10 : 0.0021    precision@10 : 0.0002\n",
      "valid result: \n",
      "recall@10 : 0.0021    mrr@10 : 0.0014    ndcg@10 : 0.0016    hit@10 : 0.0021    precision@10 : 0.0002\n",
      "25 Jun 14:45    INFO  epoch 8 training [time: 3.68s, train loss: 39.1546]\n",
      "epoch 8 training [time: 3.68s, train loss: 39.1546]\n",
      "epoch 8 training [time: 3.68s, train loss: 39.1546]\n",
      "epoch 8 training [time: 3.68s, train loss: 39.1546]\n",
      "25 Jun 14:45    INFO  epoch 8 evaluating [time: 0.22s, valid_score: 0.001600]\n",
      "epoch 8 evaluating [time: 0.22s, valid_score: 0.001600]\n",
      "epoch 8 evaluating [time: 0.22s, valid_score: 0.001600]\n",
      "epoch 8 evaluating [time: 0.22s, valid_score: 0.001600]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0016    ndcg@10 : 0.0018    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0016    ndcg@10 : 0.0018    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0016    ndcg@10 : 0.0018    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0016    ndcg@10 : 0.0018    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "25 Jun 14:45    INFO  Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "Saving current: saved\\GRU4Rec-Jun-25-2024_14-44-52.pth\n",
      "25 Jun 14:45    INFO  epoch 9 training [time: 8.23s, train loss: 38.6306]\n",
      "epoch 9 training [time: 8.23s, train loss: 38.6306]\n",
      "epoch 9 training [time: 8.23s, train loss: 38.6306]\n",
      "epoch 9 training [time: 8.23s, train loss: 38.6306]\n",
      "25 Jun 14:45    INFO  epoch 9 evaluating [time: 0.58s, valid_score: 0.001400]\n",
      "epoch 9 evaluating [time: 0.58s, valid_score: 0.001400]\n",
      "epoch 9 evaluating [time: 0.58s, valid_score: 0.001400]\n",
      "epoch 9 evaluating [time: 0.58s, valid_score: 0.001400]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0014    ndcg@10 : 0.0016    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0014    ndcg@10 : 0.0016    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0014    ndcg@10 : 0.0016    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "valid result: \n",
      "recall@10 : 0.0025    mrr@10 : 0.0014    ndcg@10 : 0.0016    hit@10 : 0.0025    precision@10 : 0.0003\n",
      "25 Jun 14:45    INFO  epoch 10 training [time: 9.39s, train loss: 38.1207]\n",
      "epoch 10 training [time: 9.39s, train loss: 38.1207]\n",
      "epoch 10 training [time: 9.39s, train loss: 38.1207]\n",
      "epoch 10 training [time: 9.39s, train loss: 38.1207]\n",
      "25 Jun 14:45    INFO  epoch 10 evaluating [time: 0.61s, valid_score: 0.000300]\n",
      "epoch 10 evaluating [time: 0.61s, valid_score: 0.000300]\n",
      "epoch 10 evaluating [time: 0.61s, valid_score: 0.000300]\n",
      "epoch 10 evaluating [time: 0.61s, valid_score: 0.000300]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0003    ndcg@10 : 0.0004    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0003    ndcg@10 : 0.0004    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0003    ndcg@10 : 0.0004    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0003    ndcg@10 : 0.0004    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "25 Jun 14:45    INFO  epoch 11 training [time: 9.50s, train loss: 37.9203]\n",
      "epoch 11 training [time: 9.50s, train loss: 37.9203]\n",
      "epoch 11 training [time: 9.50s, train loss: 37.9203]\n",
      "epoch 11 training [time: 9.50s, train loss: 37.9203]\n",
      "25 Jun 14:45    INFO  epoch 11 evaluating [time: 0.61s, valid_score: 0.000500]\n",
      "epoch 11 evaluating [time: 0.61s, valid_score: 0.000500]\n",
      "epoch 11 evaluating [time: 0.61s, valid_score: 0.000500]\n",
      "epoch 11 evaluating [time: 0.61s, valid_score: 0.000500]\n",
      "25 Jun 14:45    INFO  valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0005    ndcg@10 : 0.0006    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0005    ndcg@10 : 0.0006    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0005    ndcg@10 : 0.0006    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0005    ndcg@10 : 0.0006    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "25 Jun 14:46    INFO  epoch 12 training [time: 9.47s, train loss: 37.6198]\n",
      "epoch 12 training [time: 9.47s, train loss: 37.6198]\n",
      "epoch 12 training [time: 9.47s, train loss: 37.6198]\n",
      "epoch 12 training [time: 9.47s, train loss: 37.6198]\n",
      "25 Jun 14:46    INFO  epoch 12 evaluating [time: 0.64s, valid_score: 0.000600]\n",
      "epoch 12 evaluating [time: 0.64s, valid_score: 0.000600]\n",
      "epoch 12 evaluating [time: 0.64s, valid_score: 0.000600]\n",
      "epoch 12 evaluating [time: 0.64s, valid_score: 0.000600]\n",
      "25 Jun 14:46    INFO  valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "25 Jun 14:46    INFO  epoch 13 training [time: 9.52s, train loss: 37.5066]\n",
      "epoch 13 training [time: 9.52s, train loss: 37.5066]\n",
      "epoch 13 training [time: 9.52s, train loss: 37.5066]\n",
      "epoch 13 training [time: 9.52s, train loss: 37.5066]\n",
      "25 Jun 14:46    INFO  epoch 13 evaluating [time: 0.48s, valid_score: 0.000600]\n",
      "epoch 13 evaluating [time: 0.48s, valid_score: 0.000600]\n",
      "epoch 13 evaluating [time: 0.48s, valid_score: 0.000600]\n",
      "epoch 13 evaluating [time: 0.48s, valid_score: 0.000600]\n",
      "25 Jun 14:46    INFO  valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0006    ndcg@10 : 0.0007    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0006    ndcg@10 : 0.0007    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0006    ndcg@10 : 0.0007    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0006    ndcg@10 : 0.0007    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "25 Jun 14:46    INFO  epoch 14 training [time: 9.70s, train loss: 37.4112]\n",
      "epoch 14 training [time: 9.70s, train loss: 37.4112]\n",
      "epoch 14 training [time: 9.70s, train loss: 37.4112]\n",
      "epoch 14 training [time: 9.70s, train loss: 37.4112]\n",
      "25 Jun 14:46    INFO  epoch 14 evaluating [time: 0.62s, valid_score: 0.000600]\n",
      "epoch 14 evaluating [time: 0.62s, valid_score: 0.000600]\n",
      "epoch 14 evaluating [time: 0.62s, valid_score: 0.000600]\n",
      "epoch 14 evaluating [time: 0.62s, valid_score: 0.000600]\n",
      "25 Jun 14:46    INFO  valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0006    ndcg@10 : 0.0007    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0006    ndcg@10 : 0.0007    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0006    ndcg@10 : 0.0007    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0008    mrr@10 : 0.0006    ndcg@10 : 0.0007    hit@10 : 0.0008    precision@10 : 0.0001\n",
      "25 Jun 14:46    INFO  epoch 15 training [time: 9.59s, train loss: 37.3246]\n",
      "epoch 15 training [time: 9.59s, train loss: 37.3246]\n",
      "epoch 15 training [time: 9.59s, train loss: 37.3246]\n",
      "epoch 15 training [time: 9.59s, train loss: 37.3246]\n",
      "25 Jun 14:46    INFO  epoch 15 evaluating [time: 0.63s, valid_score: 0.000600]\n",
      "epoch 15 evaluating [time: 0.63s, valid_score: 0.000600]\n",
      "epoch 15 evaluating [time: 0.63s, valid_score: 0.000600]\n",
      "epoch 15 evaluating [time: 0.63s, valid_score: 0.000600]\n",
      "25 Jun 14:46    INFO  valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "25 Jun 14:46    INFO  epoch 16 training [time: 9.12s, train loss: 37.2298]\n",
      "epoch 16 training [time: 9.12s, train loss: 37.2298]\n",
      "epoch 16 training [time: 9.12s, train loss: 37.2298]\n",
      "epoch 16 training [time: 9.12s, train loss: 37.2298]\n",
      "25 Jun 14:46    INFO  epoch 16 evaluating [time: 0.25s, valid_score: 0.000600]\n",
      "epoch 16 evaluating [time: 0.25s, valid_score: 0.000600]\n",
      "epoch 16 evaluating [time: 0.25s, valid_score: 0.000600]\n",
      "epoch 16 evaluating [time: 0.25s, valid_score: 0.000600]\n",
      "25 Jun 14:46    INFO  valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "valid result: \n",
      "recall@10 : 0.0013    mrr@10 : 0.0006    ndcg@10 : 0.0008    hit@10 : 0.0013    precision@10 : 0.0001\n",
      "25 Jun 14:46    INFO  epoch 17 training [time: 3.79s, train loss: 37.1319]\n",
      "epoch 17 training [time: 3.79s, train loss: 37.1319]\n",
      "epoch 17 training [time: 3.79s, train loss: 37.1319]\n",
      "epoch 17 training [time: 3.79s, train loss: 37.1319]\n",
      "25 Jun 14:46    INFO  epoch 17 evaluating [time: 0.21s, valid_score: 0.000100]\n",
      "epoch 17 evaluating [time: 0.21s, valid_score: 0.000100]\n",
      "epoch 17 evaluating [time: 0.21s, valid_score: 0.000100]\n",
      "epoch 17 evaluating [time: 0.21s, valid_score: 0.000100]\n",
      "25 Jun 14:46    INFO  valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0001    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0001    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0001    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0001    hit@10 : 0.0004    precision@10 : 0.0\n",
      "25 Jun 14:46    INFO  epoch 18 training [time: 4.07s, train loss: 37.0534]\n",
      "epoch 18 training [time: 4.07s, train loss: 37.0534]\n",
      "epoch 18 training [time: 4.07s, train loss: 37.0534]\n",
      "epoch 18 training [time: 4.07s, train loss: 37.0534]\n",
      "25 Jun 14:46    INFO  epoch 18 evaluating [time: 0.20s, valid_score: 0.000100]\n",
      "epoch 18 evaluating [time: 0.20s, valid_score: 0.000100]\n",
      "epoch 18 evaluating [time: 0.20s, valid_score: 0.000100]\n",
      "epoch 18 evaluating [time: 0.20s, valid_score: 0.000100]\n",
      "25 Jun 14:46    INFO  valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0002    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0002    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0002    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0002    hit@10 : 0.0004    precision@10 : 0.0\n",
      "25 Jun 14:47    INFO  epoch 19 training [time: 3.86s, train loss: 36.9600]\n",
      "epoch 19 training [time: 3.86s, train loss: 36.9600]\n",
      "epoch 19 training [time: 3.86s, train loss: 36.9600]\n",
      "epoch 19 training [time: 3.86s, train loss: 36.9600]\n",
      "25 Jun 14:47    INFO  epoch 19 evaluating [time: 0.24s, valid_score: 0.000100]\n",
      "epoch 19 evaluating [time: 0.24s, valid_score: 0.000100]\n",
      "epoch 19 evaluating [time: 0.24s, valid_score: 0.000100]\n",
      "epoch 19 evaluating [time: 0.24s, valid_score: 0.000100]\n",
      "25 Jun 14:47    INFO  valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0001    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0001    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0001    hit@10 : 0.0004    precision@10 : 0.0\n",
      "valid result: \n",
      "recall@10 : 0.0004    mrr@10 : 0.0001    ndcg@10 : 0.0001    hit@10 : 0.0004    precision@10 : 0.0\n",
      "25 Jun 14:47    INFO  Finished training, best eval result in epoch 8\n",
      "Finished training, best eval result in epoch 8\n",
      "Finished training, best eval result in epoch 8\n",
      "Finished training, best eval result in epoch 8\n"
     ]
    }
   ],
   "source": [
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016 OrderedDict([('recall@10', 0.0025), ('mrr@10', 0.0016), ('ndcg@10', 0.0018), ('hit@10', 0.0025), ('precision@10', 0.0003)])\n"
     ]
    }
   ],
   "source": [
    "print(best_valid_score, best_valid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recbole.trainer.trainer.Trainer at 0x22f0ce1fb10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])(config, model)\n",
    "trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recbole.trainer.trainer.Trainer at 0x22f0ce1fb10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.eval_collector.data_collect(train_data)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Jun 14:48    INFO  Loading model structure and parameters from saved/latest.pth\n",
      "Loading model structure and parameters from saved/latest.pth\n",
      "Loading model structure and parameters from saved/latest.pth\n",
      "Loading model structure and parameters from saved/latest.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('recall@10', 0.0031), ('mrr@10', 0.0009), ('ndcg@10', 0.0014), ('hit@10', 0.0031), ('precision@10', 0.0003)])\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file = \"saved/latest.pth\"\n",
    "test_result = trainer.evaluate(test_data, model_file=checkpoint_file)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
